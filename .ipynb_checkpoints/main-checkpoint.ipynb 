{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¦¾ Detectron2 + COCO3200 è®­ç»ƒä¸å¯è§†åŒ– (é˜¿é‡Œäº‘ DSW å¯ç”¨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£… detectron2ï¼ˆå·²å®‰è£…å¯è·³è¿‡ï¼‰\n",
    "# !pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu118/torch2.0/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.utils.visualizer import Visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ›¿æ¢ä¸ºä½ æœ¬åœ°çš„è·¯å¾„\n",
    "train_json = \"/mnt/workspace/small_coco_train/datasets/coco3200/annotations/instances_train2017.json\"\n",
    "train_img = \"/mnt/workspace/small_coco_train/datasets/coco3200/train2017\"\n",
    "val_json = \"/mnt/workspace/small_coco_train/datasets/coco3200/annotations/instances_val2017.json\"\n",
    "val_img = \"/mnt/workspace/small_coco_train/datasets/coco3200/val2017\"\n",
    "\n",
    "register_coco_instances(\"my_coco_train\", {}, train_json, train_img)\n",
    "register_coco_instances(\"my_coco_val\", {}, val_json, val_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_json, \"r\") as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "categories = coco_data[\"categories\"]\n",
    "class_names = [cat[\"name\"] for cat in categories]\n",
    "\n",
    "MetadataCatalog.get(\"my_coco_train\").thing_classes = class_names\n",
    "metadata = MetadataCatalog.get(\"my_coco_train\")\n",
    "num_classes = len(metadata.thing_classes)\n",
    "\n",
    "print(\"ç±»åˆ«æ•°é‡:\", num_classes)\n",
    "print(\"ç±»åˆ«å:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "\n",
    "cfg.DATASETS.TRAIN = (\"my_coco_train\",)\n",
    "cfg.DATASETS.TEST = (\"my_coco_val\",)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = num_classes\n",
    "\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "cfg.SOLVER.MAX_ITER = 1000\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.OUTPUT_DIR = \"./output_my_coco\"\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ–¼ï¸ å¯è§†åŒ–è®­ç»ƒé›†å›¾åƒä¸æ ‡æ³¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dicts = DatasetCatalog.get(\"my_coco_train\")\n",
    "\n",
    "for d in random.sample(dataset_dicts, 3):\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    v = Visualizer(img[:, :, ::-1], metadata=metadata, scale=0.5)\n",
    "    out = v.draw_dataset_dict(d)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(out.get_image())\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” å¯è§†åŒ–é¢„æµ‹ç»“æœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½æ¨¡å‹å¹¶é¢„æµ‹éªŒè¯é›†\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "val_dataset_dicts = DatasetCatalog.get(\"my_coco_val\")\n",
    "\n",
    "for d in random.sample(val_dataset_dicts, 3):\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(img)\n",
    "\n",
    "    v = Visualizer(img[:, :, ::-1], metadata=metadata, scale=0.5)\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(out.get_image())\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ æŸ¥çœ‹è®­ç»ƒæ›²çº¿ï¼ˆå»ºè®®ç”¨ DSW å·¥å…·æ æŒ‰é’®ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./output_my_coco"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
